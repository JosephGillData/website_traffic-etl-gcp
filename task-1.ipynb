{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from google.cloud import storage\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google.cloud import bigquery\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = (\n",
    "  os.path.dirname(os.path.abspath(__file__))\n",
    "  if '__file__' in locals()\n",
    "  else os.getcwd()\n",
    ")\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv(os.path.join(current_directory, \".env\"))\n",
    "# Resolve credentials path relative to project root\n",
    "credentials_file = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "credentials_path = os.path.join(current_directory, credentials_file)\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: canvas-radio-396115\n",
      "Service account: joegilldata@canvas-radio-396115.iam.gserviceaccount.com\n",
      "GOOGLE_APPLICATION_CREDENTIALS: C:\\Users\\josep\\software\\git\\sky-task-1\\canvas-radio-396115-0303f86c52a3.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.auth import default\n",
    "\n",
    "creds, project_id = default()\n",
    "print(\"Project:\", project_id)\n",
    "print(\"Service account:\", getattr(creds, \"service_account_email\", \"unknown\"))\n",
    "print(\"GOOGLE_APPLICATION_CREDENTIALS:\", os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â convert the .xls file to .csv\n",
    "\n",
    "today = datetime.now().strftime('%y-%m-%d %H:%M')\n",
    "df = pd.read_excel('./data/traffic_spreadsheet.xls')\n",
    "df['time'] = df['time'].dt.strftime('%y-%m-%d %H:%M')\n",
    "df['created_at'] = today\n",
    "df.to_csv('data/traffic_spreadsheet.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/traffic_spreadsheet.csv uploaded to sky_traffic_data/traffic_spreadsheet_26-01-06 18:36.csv\n"
     ]
    }
   ],
   "source": [
    "# upload the traffic_spreadsheet.csv file to a Google Cloud Storage\n",
    "\n",
    "bucket_name = 'sky_traffic_data'\n",
    "destination_blob_name = f\"traffic_spreadsheet_{today}.csv\" # i added todays date so that files aren't overwritten on upload\n",
    "local_file_path = 'data/traffic_spreadsheet.csv' # data we are uploading\n",
    "\n",
    "client = storage.Client() # create a storage bucket client\n",
    "bucket = client.bucket(bucket_name)\n",
    "blob = bucket.blob(destination_blob_name)\n",
    "blob.upload_from_filename(local_file_path) # upload the local file to the bucket\n",
    "\n",
    "print(f'File {local_file_path} uploaded to {bucket_name}/{destination_blob_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoadJob<project=canvas-radio-396115, location=EU, id=ef38a534-cc27-4142-925a-7052319b084a>\n"
     ]
    }
   ],
   "source": [
    "# load data from Cloud Storage to BigQuery\n",
    "\n",
    "gcs_uri = f\"gs://sky_traffic_data/traffic_spreadsheet_{today}.csv\"\n",
    "dataset_id = 'sky_transport_dataset'\n",
    "table_id = 'sky_transport_table'\n",
    "\n",
    "bq_client = bigquery.Client() # create a BigQuery client\n",
    "job_config = bigquery.LoadJobConfig() # configure the job to load data\n",
    "job_config.source_format = bigquery.SourceFormat.CSV\n",
    "load_job = bq_client.load_table_from_uri(gcs_uri, dataset_id + '.' + table_id, job_config=job_config) # load data from GCS to BigQuery\n",
    "\n",
    "print(load_job.result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
